{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alivWB24K_5S"
   },
   "source": [
    "# **Music Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ll2E42N1K_5d"
   },
   "source": [
    "# **Milestone 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWO4C8KsK_5e"
   },
   "source": [
    "Now that we have explored the data, let's apply different algorithms to build recommendation systems.\n",
    "\n",
    "**Note:** Use the shorter version of the data, i.e., the data after the cutoffs as used in Milestone 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EExJfIi1sKA"
   },
   "source": [
    "## **Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MF7IjMOs1vsN"
   },
   "outputs": [],
   "source": [
    "# Load the dataset you have saved at the end of milestone 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ituk9wA4Idib"
   },
   "source": [
    "### **Popularity-Based Recommendation Systems**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "462hsbxaI1ED"
   },
   "source": [
    "Let's take the count and sum of play counts of the songs and build the popularity recommendation systems based on the sum of play counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXhBZlDE-jEu"
   },
   "outputs": [],
   "source": [
    "# Calculating average play_count\n",
    "average_count = df_final._____________        # Hint: Use groupby function on the song_id column\n",
    "\n",
    "# Calculating the frequency a song is played\n",
    "play_freq = df_final._________________        # Hint: Use groupby function on the song_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2XYdXvWdyys"
   },
   "outputs": [],
   "source": [
    "# Making a dataframe with the average_count and play_freq\n",
    "final_play = pd.DataFrame({'avg_count':_________, 'play_freq':______})\n",
    "\n",
    "# Let us see the first five records of the final_play dataset\n",
    "final_play.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnCT-A7RK_5g"
   },
   "source": [
    "Now, let's create a function to find the top n songs for a recommendation based on the average play count of song. We can also add a threshold for a minimum number of playcounts for a song to be considered for recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QiT9FV3GNCrb"
   },
   "outputs": [],
   "source": [
    "# Build the function to find top n songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpZt_BeXgz4F"
   },
   "outputs": [],
   "source": [
    "# Recommend top 10 songs using the function defined above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gf13HrPPJeWT"
   },
   "source": [
    "### **User User Similarity-Based Collaborative Filtering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROcEpduohdua"
   },
   "source": [
    "To build the user-user-similarity-based and subsequent models we will use the \"surprise\" library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKLrKn8IfGjk"
   },
   "outputs": [],
   "source": [
    "# Install the surprise package using pip. Uncomment and run the below code to do the same\n",
    "# !pip install surprise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJ1wEylUpexj"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# To compute the accuracy of models\n",
    "from surprise import accuracy\n",
    "\n",
    "# This class is used to parse a file containing play_counts, data should be in structure - user; item; play_count\n",
    "from surprise.reader import Reader\n",
    "\n",
    "# Class for loading datasets\n",
    "from surprise.dataset import Dataset\n",
    "\n",
    "# For tuning model hyperparameters\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# For splitting the data in train and test dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# For implementing similarity-based recommendation system\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "# For implementing matrix factorization based recommendation system\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "\n",
    "# For implementing KFold cross-validation\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "# For implementing clustering-based recommendation system\n",
    "from surprise import CoClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBW4BUhWTsnm"
   },
   "source": [
    "### Some useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhFa_4aHHchr"
   },
   "source": [
    "Below is the function to calculate precision@k and recall@k, RMSE and F1_Score@k to evaluate the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOvOgjGWrMVV"
   },
   "source": [
    "**Think About It:** Which metric should be used for this problem to compare different models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rxn-GahOTsnm"
   },
   "outputs": [],
   "source": [
    "# The function to calulate the RMSE, precision@k, recall@k, and F_1 score\n",
    "def precision_recall_at_k(model, k = 30, threshold = 1.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    \n",
    "    # Making predictions on the test data\n",
    "    predictions=model.test(testset)\n",
    "    \n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key = lambda x : x[0], reverse = True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[ : k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[ : k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set Precision to 0 when n_rec_k is 0\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set Recall to 0 when n_rel is 0\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    \n",
    "    # Mean of all the predicted precisions are calculated\n",
    "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
    "\n",
    "    # Mean of all the predicted recalls are calculated\n",
    "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
    "    \n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "    # Command to print the overall precision\n",
    "    print('Precision: ', precision)\n",
    "\n",
    "    # Command to print the overall recall\n",
    "    print('Recall: ', recall)\n",
    "    \n",
    "    # Formula to compute the F-1 score\n",
    "    print('F_1 score: ', round((2 * precision * recall) / (precision + recall), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcmLRxH4IjfG"
   },
   "source": [
    "**Think About It:** In the function precision_recall_at_k above the threshold value used is 1.5. How precision and recall are affected by changing the threshold? What is the intuition behind using the threshold value of 1.5? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGfYDiOCpe4X"
   },
   "outputs": [],
   "source": [
    "# Instantiating Reader scale with expected rating scale \n",
    "reader = Reader(rating_scale=____) #use rating scale (0, 5)\n",
    "\n",
    "# Loading the dataset\n",
    "data = Dataset.load_from_df(df_final[[______, _______, ____]], reader) # Take only \"user_id\",\"song_id\", and \"play_count\"\n",
    "\n",
    "# Splitting the data into train and test dataset\n",
    "trainset, testset = train_test_split(data, test_size=____, random_state = 42) # Take test_size = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuTmLjUP1aED"
   },
   "source": [
    "**Think About It:** How changing the test size would change the results and outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vO3FL7iape8A",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build the default user-user-similarity model\n",
    "sim_options = {'name': _________,\n",
    "               'user_based':______}\n",
    "\n",
    "# KNN algorithm is used to find desired similar items\n",
    "sim_user_user = KNNBasic(_________) # Use random_state = 1 \n",
    "\n",
    "# Train the algorithm on the trainset, and predict play_count for the testset\n",
    "sim_user_user.fit(_________)\n",
    "\n",
    "# Let us compute precision@k, recall@k, and f_1 score with k = 30\n",
    "precision_recall_at_k(_____________) # Use sim_user_user model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzcdlWmer6GA"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sxd23bZ9pe_x"
   },
   "outputs": [],
   "source": [
    "# Predicting play_count for a sample user with a listened song\n",
    "sim_user_user.predict(_____, ______, r_ui = 2, verbose = True) # Use user id 6958 and song_id 1671"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbFcBj1PpfEV"
   },
   "outputs": [],
   "source": [
    "# Predicting play_count for a sample user with a song not-listened by the user\n",
    "sim_user_user.predict(____, _____, verbose = True) # Use user_id 6958 and song_id 3232"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9EVM7DysC47"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lt1QBiylsIOm"
   },
   "source": [
    "Now, let's try to tune the model and see if we can improve the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3diJPL7-tVw"
   },
   "outputs": [],
   "source": [
    "# Setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {'k': [10, 20, 30], 'min_k': [3, 6, 9],\n",
    "              'sim_options': {'name': [\"cosine\", 'pearson', \"pearson_baseline\"],\n",
    "                              'user_based': [True], \"min_support\": [2, 4]}\n",
    "              }\n",
    "\n",
    "# Performing 3-fold cross-validation to tune the hyperparameters\n",
    "\n",
    "# Fitting the data\n",
    "gs.fit(______) # Use entire data for GridSearch\n",
    "\n",
    "# Best RMSE score\n",
    "\n",
    "# Combination of parameters that gave the best RMSE score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PujRJA8X_JEJ"
   },
   "outputs": [],
   "source": [
    "# Train the best model found in above gridsearch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MH5OBZ7Nse6m"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgV63lHiq1TV"
   },
   "outputs": [],
   "source": [
    "# Predict the play count for a user who has listened to the song. Take user_id 6958, song_id 1671 and r_ui = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXO2Ztjhq1bN"
   },
   "outputs": [],
   "source": [
    "# Predict the play count for a song that is not listened to by the user (with user_id 6958)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdpJ--8QWuzz"
   },
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQ9M4pplNbWS"
   },
   "source": [
    "**Think About It:** Along with making predictions on listened and unknown songs can we get 5 nearest neighbors (most similar) to a certain song?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TbFle7cKmBJG"
   },
   "outputs": [],
   "source": [
    "# Use inner id 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3ESobDynVNI"
   },
   "source": [
    "Below we will be implementing a function where the input parameters are:\n",
    "\n",
    "- data: A **song** dataset\n",
    "- user_id: A user-id **against which we want the recommendations**\n",
    "- top_n: The **number of songs we want to recommend**\n",
    "- algo: The algorithm we want to use **for predicting the play_count**\n",
    "- The output of the function is a **set of top_n items** recommended for the given user_id based on the given algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vW9V1Tk65HlY"
   },
   "outputs": [],
   "source": [
    "def get_recommendations(data, user_id, top_n, algo):\n",
    "    \n",
    "    # Creating an empty list to store the recommended product ids\n",
    "    recommendations = []\n",
    "    \n",
    "    # Creating an user item interactions matrix \n",
    "    user_item_interactions_matrix = data.pivot_table(______________)\n",
    "    \n",
    "    # Extracting those business ids which the user_id has not visited yet\n",
    "    non_interacted_products = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
    "    \n",
    "    # Looping through each of the business ids which user_id has not interacted yet\n",
    "    for item_id in non_interacted_products:\n",
    "        \n",
    "        # Predicting the ratings for those non visited restaurant ids by this user\n",
    "        est = ___________________\n",
    "        \n",
    "        # Appending the predicted ratings\n",
    "        recommendations.append(_______________)\n",
    "\n",
    "    # Sorting the predicted ratings in descending order\n",
    "    recommendations.sort(key = lambda x : x[1], reverse = True)\n",
    "\n",
    "    return recommendations[:top_n] # Returing top n highest predicted rating products for this user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWbR85mI5Hrk"
   },
   "outputs": [],
   "source": [
    "# Make top 5 recommendations for user_id 6958 with a similarity-based recommendation engine\n",
    "recommendations =___________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5WfIX0Z6_q2"
   },
   "outputs": [],
   "source": [
    "# Building the dataframe for above recommendations with columns \"song_id\" and \"predicted_ratings\"\n",
    "pd.DataFrame(_________________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyhThMOttWjj"
   },
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghwEJY2e7INB"
   },
   "source": [
    "### Correcting the play_counts and Ranking the above songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "39Hs7ZbO9v3O"
   },
   "outputs": [],
   "source": [
    "def ranking_songs(recommendations, final_rating):\n",
    "  # Sort the songs based on play counts\n",
    "  ranked_songs = final_rating.loc[[items[0] for items in recommendations]].sort_values('play_freq', ascending = False)[['play_freq']].reset_index()\n",
    "\n",
    "  # Merge with the recommended songs to get predicted play_count\n",
    "  ranked_songs = ranked_songs.merge(pd.DataFrame(recommendations, columns = [__________, ___________]), on = ____________, how = 'inner')\n",
    "\n",
    "  # Rank the songs based on corrected play_counts\n",
    "  ranked_songs['corrected_ratings'] = ranked_songs['predicted_ratings'] - 1 / np.sqrt(ranked_songs['play_freq'])\n",
    "\n",
    "  # Sort the songs based on corrected play_counts\n",
    "  ranked_songs = ________________\n",
    "  \n",
    "  return ranked_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQvst41lOoMX"
   },
   "source": [
    "**Think About It:** In the above function to correct the predicted play_count a quantity 1/np.sqrt(n) is subtracted. What is the intuition behind it? Is it also possible to add this quantity instead of subtracting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xoiAL_vH8miC"
   },
   "outputs": [],
   "source": [
    "# Applying the ranking_songs function on the final_play data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOwwGsH8toLG"
   },
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgbzJKk7Tsnr"
   },
   "source": [
    "### Item Item Similarity-based collaborative filtering recommendation systems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W5RMcdzjTsns",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Apply the item-item similarity collaborative filtering model with random_state = 1 and evaluate the model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfdIJ6XWunx0"
   },
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yILOxXRTsns"
   },
   "outputs": [],
   "source": [
    "# Predicting play count for a sample user_id 6958 and song (with song_id 1671) heard by the user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSn8oK3JZsTc"
   },
   "outputs": [],
   "source": [
    "# Predict the play count for a user that has not listened to the song (with song_id 1671)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxE9fJ8Dupby"
   },
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5bcZ3HgTsnt"
   },
   "outputs": [],
   "source": [
    "# Apply grid search for enhancing model performance\n",
    "\n",
    "# Setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {'k': [10, 20, 30], 'min_k': [3, 6, 9],\n",
    "              'sim_options': {'name': [\"cosine\", 'pearson', \"pearson_baseline\"],\n",
    "                              'user_based': [False], \"min_support\": [2, 4]}\n",
    "              }\n",
    "\n",
    "# Performing 3-fold cross-validation to tune the hyperparameters\n",
    "gs = \n",
    "\n",
    "# Fitting the data\n",
    "gs.fit(_____)\n",
    "\n",
    "# Find the best RMSE score\n",
    "\n",
    "# Extract the combination of parameters that gave the best RMSE score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXLxjLEQYvWk"
   },
   "source": [
    "**Think About It:** How do the parameters affect the performance of the model? Can we improve the performance of the model further? Check the list of hyperparameters [here](https://surprise.readthedocs.io/en/stable/knn_inspired.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSeiM1qeTsnt"
   },
   "outputs": [],
   "source": [
    "# Apply the best modle found in the grid search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxXelRIluvfh"
   },
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gIBRRvdoTsnt"
   },
   "outputs": [],
   "source": [
    "# Predict the play_count by a user(user_id 6958) for the song (song_id 1671)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNEgcI9PTsnu"
   },
   "outputs": [],
   "source": [
    "# Predicting play count for a sample user_id 6958 with song_id 3232 which is not heard by the user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yf3kDSepuwcw"
   },
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRJS4oDFTsnu"
   },
   "outputs": [],
   "source": [
    "# Find five most similar items to the item with inner id 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rzoEbuZFTsnu"
   },
   "outputs": [],
   "source": [
    "# Making top 5 recommendations for user_id 6958 with item_item_similarity-based recommendation engine\n",
    "recommendations = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kXVTiysTsnv"
   },
   "outputs": [],
   "source": [
    "# Building the dataframe for above recommendations with columns \"song_id\" and \"predicted_play_count\"\n",
    "pd.DataFrame(_______________)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gewfmTATsnv"
   },
   "outputs": [],
   "source": [
    "# Applying the ranking_songs function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ore9XTFgv5Np"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKgJpSA9vOOL"
   },
   "source": [
    "### Model Based Collaborative Filtering - Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJynidJCw-ti"
   },
   "source": [
    "Model-based Collaborative Filtering is a **personalized recommendation system**, the recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07-2PT5Ssjqm"
   },
   "outputs": [],
   "source": [
    "# Build baseline model using svd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWIhfdxXsjqm"
   },
   "outputs": [],
   "source": [
    "# Making prediction for user (with user_id 6958) to song (with song_id 1671), take r_ui = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APm-uMSvcAMf"
   },
   "outputs": [],
   "source": [
    "# Making a prediction for the user who has not listened to the song (song_id 3232)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23tnRUJJxWTR"
   },
   "source": [
    "#### Improving matrix factorization based recommendation system by tuning its hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bM81V_hvtwv"
   },
   "outputs": [],
   "source": [
    "# Set the parameter space to tune\n",
    "param_grid = {'n_epochs': [10, 20, 30], 'lr_all': [0.001, 0.005, 0.01],\n",
    "              'reg_all': [0.2, 0.4, 0.6]}\n",
    "\n",
    "# Performe 3-fold grid-search cross-validation\n",
    "gs = \n",
    "\n",
    "# Fitting data\n",
    "\n",
    "# Best RMSE score\n",
    "\n",
    "# Combination of parameters that gave the best RMSE score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSgBRcL1xnVC"
   },
   "source": [
    "**Think About It**: How do the parameters affect the performance of the model? Can we improve the performance of the model further? Check the available hyperparameters [here](https://surprise.readthedocs.io/en/stable/matrix_factorization.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TA_7xe-nnhuu"
   },
   "outputs": [],
   "source": [
    "# Building the optimized SVD model using optimal hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3t5JdBmxz8l"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6C1PAfboM8_"
   },
   "outputs": [],
   "source": [
    "# Using svd_algo_optimized model to recommend for userId 6958 and song_id 1671\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1xjn3kOoQyg"
   },
   "outputs": [],
   "source": [
    "# Using svd_algo_optimized model to recommend for userId 6958 and song_id 3232 with unknown baseline rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qm732Wuvy76R"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LGeE2EB_n90"
   },
   "outputs": [],
   "source": [
    "# Getting top 5 recommendations for user_id 6958 using \"svd_optimized\" algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ngiGSJU818M"
   },
   "outputs": [],
   "source": [
    "# Ranking songs based on above recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SepUU1Efy_9Z"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57b31de5"
   },
   "source": [
    "### Cluster Based Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Xv2AZCszCdN"
   },
   "source": [
    "In **clustering-based recommendation systems**, we explore the **similarities and differences** in people's tastes in songs based on how they rate different songs. We cluster similar users together and recommend songs to a user based on play_counts from other users in the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0c4b20e4"
   },
   "outputs": [],
   "source": [
    "# Make baseline clustering model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11dbdc0f"
   },
   "outputs": [],
   "source": [
    "# Making prediction for user_id 6958 and song_id 1671\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dab1aaed"
   },
   "outputs": [],
   "source": [
    "# Making prediction for user (userid 6958) for a song(song_id 3232) not heard by the user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2fd66f5"
   },
   "source": [
    "#### Improving clustering-based recommendation system by tuning its hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efe7d8e6"
   },
   "outputs": [],
   "source": [
    "# Set the parameter space to tune\n",
    "param_grid = {'n_cltr_u': [5, 6, 7, 8], 'n_cltr_i': [5, 6, 7, 8], 'n_epochs': [10, 20, 30]}\n",
    "\n",
    "# Performing 3-fold grid search cross-validation\n",
    "\n",
    "# Fitting data\n",
    "\n",
    "# Best RMSE score\n",
    "\n",
    "# Combination of parameters that gave the best RMSE score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CS6aMVJLyj21"
   },
   "source": [
    "**Think About It**: How do the parameters affect the performance of the model? Can we improve the performance of the model further? Check the available hyperparameters [here](https://surprise.readthedocs.io/en/stable/co_clustering.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5a7a8a30"
   },
   "outputs": [],
   "source": [
    "# Train the tuned Coclustering algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-Jvce1gznKa"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ba5b26b"
   },
   "outputs": [],
   "source": [
    "# Using co_clustering_optimized model to recommend for userId 6958 and song_id 1671\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ec582940"
   },
   "outputs": [],
   "source": [
    "# Use Co_clustering based optimized model to recommend for userId 6958 and song_id 3232 with unknown baseline rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjGUSMqrzoDH"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df9e28ba"
   },
   "source": [
    "#### Implementing the recommendation algorithm based on optimized CoClustering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0f36e15"
   },
   "outputs": [],
   "source": [
    "# Getting top 5 recommendations for user_id 6958 using \"Co-clustering based optimized\" algorithm\n",
    "clustering_recommendations = _______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1696941"
   },
   "source": [
    "### Correcting the play_count and Ranking the above songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c186f13b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ranking songs based on the above recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uJ_nZjBzvKH"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5U56oSNsR-F2"
   },
   "source": [
    "### Content Based Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aTEqaOjhoEg"
   },
   "source": [
    "**Think About It:** So far we have only used the play_count of songs to find recommendations but we have other information/features on songs as well. Can we take those song features into account?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhUx2jgp4frC"
   },
   "outputs": [],
   "source": [
    "df_small = df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UX826CsjR-F3"
   },
   "outputs": [],
   "source": [
    "# Concatenate the \"title\", \"release\", \"artist_name\" columns to create a different column named \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdXw4U-wR-F4"
   },
   "outputs": [],
   "source": [
    "# Select the columns 'user_id', 'song_id', 'play_count', 'title', 'text' from df_small data\n",
    "\n",
    "# Drop the duplicates from the title column\n",
    "\n",
    "# Set the title column as the index\n",
    "\n",
    "# See the first 5 records of the df_small dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDcYHwZTR-F5"
   },
   "outputs": [],
   "source": [
    "# Create the series of indices from the data\n",
    "indices =_______________\n",
    "\n",
    "indices[ : 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UINF3Nwvwfr"
   },
   "outputs": [],
   "source": [
    "# Importing necessary packages to work with text data\n",
    "import nltk\n",
    "\n",
    "# Download punkt library\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Download stopwords library\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Download wordnet \n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Import regular expression\n",
    "import re\n",
    "\n",
    "# Import word_tokenizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Import WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Import CountVectorizer and TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt2vitlnhoEg"
   },
   "source": [
    "We will create a **function to pre-process the text data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "j5QSSeUvR-F6"
   },
   "outputs": [],
   "source": [
    "# Function to tokenize the text\n",
    "def tokenize(text):\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z]\",\" \", text.lower())\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    words = [word for word in tokens if word not in stopwords.words(____)]  # Use stopwords of english\n",
    "    \n",
    "    text_lems = [WordNetLemmatizer().lemmatize(lem).strip() for lem in words]\n",
    "\n",
    "    return text_lems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RI_onIGdR-F6"
   },
   "outputs": [],
   "source": [
    "# Create tfidf vectorizer \n",
    "\n",
    "# Fit_transfrom the above vectorizer on the text column and then convert the output into an array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Beak6ODRR-F7"
   },
   "outputs": [],
   "source": [
    "# Compute the cosine similarity for the tfidf above output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Jjo3UHKhoEh"
   },
   "source": [
    " Finally, let's create a function to find most similar songs to recommend for a given song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upANOISkR-F8"
   },
   "outputs": [],
   "source": [
    "# Function that takes in song title as input and returns the top 10 recommended songs\n",
    "def recommendations(title, similar_songs):\n",
    "    \n",
    "    recommended_songs = []\n",
    "    \n",
    "    # Getting the index of the song that matches the title\n",
    "    idx = indices[indices == title].index[0]\n",
    "\n",
    "    # Creating a Series with the similarity scores in descending order\n",
    "    score_series = pd.Series(similar_songs[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # Getting the indexes of the 10 most similar songs\n",
    "    top_10_indexes = list(score_series.iloc[1 : 11].index)\n",
    "    print(top_10_indexes)\n",
    "    \n",
    "    # Populating the list with the titles of the best 10 matching songs\n",
    "    for i in top_10_indexes:\n",
    "        recommended_songs.append(list(df_small.index)[i])\n",
    "        \n",
    "    return recommended_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4EINBmkR-F8"
   },
   "source": [
    "Recommending 10 songs similar to Learn to Fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohEK5dkVR-F8"
   },
   "outputs": [],
   "source": [
    "# Make the recommendation for the song with title 'Learn To Fly'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQ7iI5QJ0oem"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6k0w-Ci6vYY4"
   },
   "source": [
    "## **Conclusion and Recommendations:** \n",
    "\n",
    "- **Refined Insights -** What are the most meaningful insights from the data relevant to the problem?\n",
    "\n",
    "- **Comparison of various techniques and their relative performance -** How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?\n",
    "\n",
    "- **Proposal for the final solution design -** What model do you propose to be adopted? Why is this the best solution to adopt?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reference_Notebook_Milestone_2_Recommendation_Systems_(1)_(2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
